---
title: "Meta-analysis of prediction model performance"
author:
  - name: Thomas Debray
    orcid: 0000-0002-1790-2719
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Meta-analysis of prediction model performance}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: "https://api.citedrive.com/bib/0d25b38b-db8f-43c4-b934-f4e2f3bd655a/references.bib?x=eyJpZCI6ICIwZDI1YjM4Yi1kYjhmLTQzYzQtYjkzNC1mNGUyZjNiZDY1NWEiLCAidXNlciI6ICIyNTA2IiwgInNpZ25hdHVyZSI6ICI0MGFkYjZhMzYyYWE5Y2U0MjQ2NWE2ZTQzNjlhMWY3NTk5MzhhNzUxZDNjYWIxNDlmYjM4NDgwOTYzMzY5YzFlIn0=/bibliography.bib"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  message = FALSE,
  warning = FALSE,
  tidy = TRUE
)
```

```{r, echo = F}
library(knitr)
library(dplyr)

# usethis::use_pkgdown_github_pages().
# pkgdown::build_site()
```

# Case Study
The [EuroSCORE II](http://www.euroscore.org/calc.html) is a commonly used scoring rule for estimating the risk of in-hospital mortality in  patients undergoing major cardiac surgery. It was developed using data from  16,828 adult patients from 43 countries. Predictors include patient characteristics (e.g. age, gender), cardiac related factors (e.g. recent MI) and surgery related factors (e.g. Surgery on thoracic aorta). In 2014, a systematic review was undertaken by @guida_performance_2014 to search articles assessing the performance of EuroSCORE II on perioperative mortality in cardiac surgery. The systematic review identified 24 eligible validation studies, 22 studies were included in the main analysis. 

In this case study, we summarize the results from these 22 studies, as well as the results from the split-sample validation contained within original development article of EuroSCORE II. We will use the **metamisc** package to derive summary estimates for the discrimination and calibration performance of EuroSCORE II, to evaluate the presence of between-study heterogeneity, and to identify potential sources of between-study heterogeneity. A step-by-step tutorial is provided by @debray_guide_2017. 

We can load the data from all 23 validation studies as follows:

```{r}
library(metafor)
library(metamisc)
data(EuroSCORE)
```

```{r, echo = F}
out <- EuroSCORE %>% mutate(mortality = sprintf("%.2f", 100*n.events/n),
                            euroscore = sprintf("%.2f", 100*Pe)) %>%
  select(Study, n, mortality, euroscore, c.index)
kable(out, col.names = c("Study", "Patients (n)", "Mortality (%)", "euroSCORE II (%)", "c-index"),
      align = "lrcc")
```


# Meta-analysis of calibration performance
Calibration refers to a model's accuracy of predicted risk probabilities, and indicates the extent to which expected outcomes (predicted from the model) and observed outcomes agree. Summarizing estimates of calibration performance is challenging because calibration plots are most often not presented, and because studies tend to report different types of summary statistics in calibration. For example, in the case study, calibration was assessed using the Hosmer-Lemeshow test, calibration plots or by comparing the observed mortality to the predicted EuroSCORE II (either overall or for groups of patients). Within each validation study, we can compare the total	number	of observed events (O) with the total number of expected (predicted)	events by deriving their ratio O:E. The total O:E ratio provides a rough indication of the overall model calibration (across the entire range of predicted risks). It	describes	whether	more	(O:E	>	1)	or	fewer	(O:E	<	1)	events	occurred		than	expected	 based	on	the	model. Whilst the O:E ratio itself was not explicitly reported in all studies, it can be calculated from other reported information:

```{r}
EuroSCORE <- EuroSCORE %>% mutate(oe = n.events/e.events)
```

The O:E ratio can also be derived from the observed and predicted mortality risk `Po` and, respectively, `Pe`:

```{r, eval = F}
EuroSCORE %>% select(Po, Pe) %>% mutate(oe = Po/Pe)
```

It is recommended to first transform extracted O:E ratios to	the	log (natural logarithm) scale before applying a meta-analysis [@snell_meta-analysis_2017].

```{r}
EuroSCORE <- EuroSCORE %>% mutate(logOE = log(oe))
```

Consequently, we need to derive the standard error of the log O:E ratio, which is approximately given as 

$$\sqrt{(1/O) - (1/N)} \approx \sqrt{1/O}$$

We can implement this as follows:

```{r}
EuroSCORE <- EuroSCORE %>% mutate(se.logOE = sqrt((1/n.events - 1/n)))
```

We can now visualise the calibration performance of EuroSCORE II across the included studies by generating a forest plot:

```{r, echo = FALSE}
metafor::forest(x = EuroSCORE$logOE, sei = EuroSCORE$se.logOE, slab = EuroSCORE$Study, 
                transf = exp, xlab = "O:E ratio", refline = 1, cex = 0.8)
```

For each validation study, the O:E ratio is provided with its 95% confidence interval. The size of the boxes indicates the	sample size of the corresponding validation study. In this forest plot, O:E	ratios appear to vary	substantially	across the included validation	studies. These results suggest that the calibration of EuroSCORE II is prone to substantial between-study heterogeneity.

In [metamisc](https://CRAN.R-project.org/package=metamisc), we can combine the aforementioned steps as follows:

```{r}
oe.ad <- oecalc(N = n, O = n.events, E = e.events, slab = Study, 
                data = EuroSCORE)
plot(oe.ad, refline = 1, sort = "no")
```

Note that if we want to derive the log O:E ratio instead, we should use:

```{r}
logoe.ad <- oecalc(N = n, O = n.events, E = e.events, 
                   slab = Study, g = "log(OE)", data = EuroSCORE)
```


## Fixed effect meta-analysis
We can now summarize the results from the included validation studies. A simple approach is to calculate a weighted average, where the estimate of each study is simply weighted by its precision. This approach is also known as fixed effect meta-analysis, where the weighted average $\mu$ is given by:

$$\mu = \dfrac{ \sum_{i=1}^{K}\left( \hat \theta_i / \left(\mathrm{SE}(\hat \theta_i)\right)^2 \right)}{ \sum_{i=1}^{K}\left( 1 /  \left(\mathrm{SE}(\hat \theta_i)\right)^2 \right) }\\$$
In this expression, $\hat \theta_i$ represent the study specific estimates for the log O:E ratio, and $K$ represents the total number of included studies. Aforementioned estimate for $\mu$ corresponds to the maximum likelihood of a fixed effect meta-analysis that assumes normality of the log O:E ratio within studies:

$$\hat \theta_i \sim \mathcal{N}\left(\mu, \left(\mathrm{SE}(\hat \theta_i)\right)^2\right)$$
We can directly calculate the pooled log O:E ratio as follows:

```{r}
mu <- sum(EuroSCORE$logOE/EuroSCORE$se.logOE**2)/sum(1/EuroSCORE$se.logOE**2)
```

Since the meta-analysis is performed using log-transformed estimates, the summary estimate for the total O:E ratio is given as $\exp(\hat \mu)$:

```{r}
exp(mu)
```

The	fixed	effect	meta-analysis	of the total O:E ratio can also be performed using **metafor**:

```{r,message=F,warning=F,echo=T,eval=T}
fit <- rma(yi = logOE, sei = se.logOE, data = EuroSCORE, method = "FE")
exp(fit$beta)
```

Alternatively, we can directly implement all of the aforementioned data preparation and meta-analysis steps using the `valmeta()` command. Hereto, we will use information on the total number of observed and expected events from each validation study, as well as the total sample size. Note that unless specified otherwise, `valmeta()` will apply the log transformation to summarize estimates of the total O:E ratio, and back-transform the results to the original scale.

```{r,message=F,warning=F,echo=T,eval=T}
valmeta(measure = "OE", O = n.events, E = e.events,  N = n, method = "FE", 
        data = EuroSCORE)
```

The pooled O:E ratio is `sprintf("%.2f", exp(mu))`, which implies that, on average, EuroSCORE II tends to yield predictions of peri-operative mortality that are too high.

Note that to obtain a summary of the total O:E ratio, we provided information on the total number of observed and expected events, as well as the total sample size. In practice, however, the total sample size may not always have been reported, and in such situations approximations can be used for estimating the standard error of the total O:E ratio. To illustrate this, we can re-run our fixed effect meta-analysis by omitting the sample size from the `valmeta()` command:

```{r,message=F,warning=F,echo=T,eval=T}
valmeta(measure = "OE", O = n.events, E = e.events, method = "FE", 
        data = EuroSCORE)
```

Results are nearly identical to the analyses where we utilized information on the sample size of the validation studies.



# References
