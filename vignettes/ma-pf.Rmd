---
title: "Meta-analysis of prognostic factors"
author:
  - name: Thomas Debray
    orcid: 0000-0002-1790-2719
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Meta-analysis of prognostic factors}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: "https://api.citedrive.com/bib/093a08ac-0337-479e-a147-17929fa7f7b0/references.bib?x=eyJpZCI6ICIwOTNhMDhhYy0wMzM3LTQ3OWUtYTE0Ny0xNzkyOWZhN2Y3YjAiLCAidXNlciI6ICI0MDA5IiwgInNpZ25hdHVyZSI6ICIwOWJiZjg2ZDJiNjk1NmQ1ODVhZTMxZmZiODI0OTgyNWYxYTEzNTQ5MzdiZjBiNzJiZjY3MTlhMTE2NGJhNzQ3In0=/bibliography.bib"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  message = FALSE,
  warning = FALSE,
  tidy = TRUE
)
```


```{r, echo = F}
library(knitr)
library(dplyr)

# usethis::use_pkgdown_github_pages().
# pkgdown::build_site()
```

# Introduction

An important task in medical research is the identification and assessment of prognostic factors. A prognostic factor is any measure that, among people with a given health condition (that is, a startpoint), is associated with a subsequent clinical outcome (an endpoint) [@riley_prognosis_2013]. Commonly investigated prognostic factors include simple measures such as age, sex, and size of tumor, but they can also include more complex factors such as abnormal levels of proteins or catecholamines and unusual genetic mutations [@sauerbrei_evidence-based_2006]. They can be useful as modifiable targets for interventions to improve outcomes, building blocks for prognostic models, or predictors of differential treatment response.

Over the past few decades, numerous prognostic factor studies have been published in the medical literature. For example, @riley_reporting_2003 identified 260 studies reporting associations for 130 different tumour markers for neuroblastoma. More recently, @tzoulaki_assessment_2009 identified 79 studies reporting the added value of 86 different markers when added to the Framingham risk score. Despite this huge research effort, the prognostic value of most traditional factors under discussion is uncertain and the usefulness of many specific markers, prognostic indices, and classification schemes is still unproven [@sauerbrei_evidence-based_2006].

This vignette aims to illustrate how the results from multiple prognostic factor studies can be summarized and how sources of between-study heterogeneity can be examined. Hereto, we will use the R packages  **metamisc** and **metafor**. The [https://cran.r-project.org/package=metafor](metafor) package provides a comprehensive collection of functions for conducting meta-analyses in R. The [https://cran.r-project.org/package=metamisc](metamisc) package provides additional functions to facilitate meta-analysis of prognosis studies. We can load these packages as follows:

```{r, message = F, warning = F}
library(metafor)
library(metamisc)
```

# Case Study

Endometrial cancer (EC) is the fourth most common malignancy in women and the most common gynecologic cancer. Overall, the 5-year survival rates for EC are approximately 78--90% for stage I, 74% for stage II, 36--57% for stage III, and 20% for stage IV. Such poor outcomes raise an urgent requirement that more accurate prognosis and predictive markers should be applied for EC to guide the therapy and monitor the disease progress for individual patients.

Several biological molecules have been proposed as prognostic biomarkers in EC. Among them, hormone receptors such as estrogen receptors (ER), progesterone receptors (PR), and human epidermal growth factor receptor 2 (HER2) are attractive because of their physiological functions. Recently, Zhang \emph{et al.} conducted a systematic review to evaluate the overall risk of these hormone receptors for endometrial cancer survival [@zhang_prognostic_2015]. This review included 16 studies recruiting 1764 patients for HER2. For each study, estimates of effect were retrieved as follows. The simplest method consisted in the direct collection of HR, odds ratio or risk ratio, and their 95% CI from the original article, with an HR of less than 1 being associated with a better outcome. If not available, the total numbers of observed deaths/cancer recurrences and the numbers of patients in each group were extracted to calculate HR. When data were only available as Kaplan-Meier curves, data were extracted from the graphical survival plots, and estimation of the HR was then performed using the described method.

We can load the data from all 16 studies in R as follows:

```{r}
data(Zhang)
```

This creates an object `Zhang` that contains the summary data from 14 studies reporting on overall survival (OS) and from 6 studies reporting on progression-free survival (PFS). A total of 14 studies assessed the relation between HER2 and overall survival. The corresponding hazard
ratios (HR) are given below:

```{r tableBaselineOS, echo = F}
out <- Zhang %>% filter(outcome == "OS") %>%
  mutate(slabel = paste0(PrimaryAuthor, ", ", year),
                        result = paste0(HR, " (",HR.025, "; ", HR.975, ")")) %>% 
  select("slabel", "Country", "Disease", "N","result")
kable(out, col.names = c("Study", "Country", "Disease", "N", "Hazard Ratio (95% CI)"),
      align = "lccrc")
```

Results suggest that the hormone receptor HER2 has prognostic value for survival but is prone to substantial between-study heterogeneity. For example, hazard ratios appear much larger for studies that were conducted in the USA. Possibly, the variation in treatment effect estimates is caused by differences in the baseline characteristics of patients (age, tumor stage, race), differences in the cutoff value of HER2, differences in received treatments, or differences in the duration of follow-up. Importantly, because estimated hazard ratios have not been adjusted for any patient-level covariates, they are particularly prone to heterogeneity in patient spectrum.



# First steps

To facilitate any quantitative analysis, information on the standard error of the different study effect sizes is needed. Estimates for the standard error can be obtained from the reported 95% confidence intervals [@altman_how_2011]. It is then commonly assumed that the log hazard ratio follows a Normal distribution, such that he standard error (SE) of the log hazard ratio is given as:

$\mathrm{SE}=(\log(u)-\log(l))/(2*1.96)$

where the upper and lower limits of the 95% CI are $u$ and $l$ respectively. We can implement this calculation as follows:

```{r,message=F,warning=F,echo=T,eval=T}
Zhang <- Zhang %>% mutate(logHR = log(HR), 
                          se.logHR =  log(HR.975/HR.025) / (2*qnorm(0.975))
                          )
```

It is often helpful to display the effect sizes of all studies in a forest plot. An advantage of the forest plot is that allows a visual inspection of the available evidence and facilitates the identification of potential between-study heterogeneity. The forest plot for overall survival can then be generated using the `forest` function in **metamisc**. This requires to provide information on the estimated hazard ratios (via the argument `theta`), as well as the bounds of their 95% confidence interval (via `theta.ci.lb` and `theta.ci.ub`). 

```{r,message=F,warning=F,echo=T,eval=T, fig.width=8, fig.height=4}
library(dplyr)

# Select the 14 studies investigating overall survival
dat_os <- Zhang %>% filter(outcome == "OS")

# Generate a forest plot of the log hazard ratio
metamisc::forest(theta = dat_os$HR, 
                 theta.ci.lb = dat_os$HR.025, 
                 theta.ci.ub = dat_os$HR.975, 
                 theta.slab = dat_os$Study, 
                 xlab = "Hazard ratio of HER2 versus OS", 
                 refline = 1)
```

We can also generate a forest plot using **metafor**:

```{r,message=F,warning=F,echo=T,eval=T}
metafor::forest(x = dat_os$HR, 
                ci.lb = dat_os$HR.025, 
                ci.ub = dat_os$HR.975, 
                slab = dat_os$Study,
                xlab = "Hazard ratio of HER2 versus OS", 
                refline = 1)
```

# Assessment of publication bias

The presence of small-study effects is a common threat to systematic reviews and meta-analyses. Small-study effects is a generic term for the phenomenon that sometimes smaller studies show different, often stronger, effects than the large ones [@debray_detecting_2018]. One possible reason is publication bias. Previously, @altman_systematic_2001 argued that it is probable that studies showing a strong (often statistically significant) prognostic ability are more likely to be published. For this reason, it is important to evaluate the potential presence of small-study effects, which can be verified by visual inspection of the funnel plot. In this plot, the estimate of the reported effect size is plotted against a measure of precision or sample size for each included study of the meta-analysis. The premise is that the scatter of plots should reflect a funnel shape, if small-study effects do not exist (provided that effect sizes are not substantially affected by the presence of between-study heterogeneity). However, when small studies are predominately in one direction (usually the direction of larger effect sizes), asymmetry will ensue.

A common approach to construct the funnel plot is to display the individual observed effect sizes on the x-axis against the corresponding standard errors on the y-axis, and to use the fixed effect summary estimate as reference value. In the absence of publication bias and heterogeneity, one would then expect to see the points forming a funnel shape, with the majority of the points falling inside of the pseudo-confidence region of the summary estimate.

```{r,message=F,warning=F,echo=T,eval=T}
res <- rma(yi = logHR, sei = se.logHR, method = "FE", data = dat_os)
funnel(res, xlab = "Log Hazard Ratio")
```

In the case study, most study estimates fall within the pseudo-confidence region, hence there appears limited evidence for publication bias.

We can formally test the presence of asymmetry in the funnel plot by evaluating whether there is an association between the estimated standard error and the estimated effect size.

```{r,message=F,warning=F,echo=T,eval=T}
regtest(x = dat_os$logHR, 
        sei = dat_os$se.logHR, 
        model = "lm", 
        predictor = "sei")
```

```{r,message=F,warning=F,echo=F,eval=T}
regfit <- regtest(x = dat_os$logHR, 
                  sei = dat_os$se.logHR, 
                  model = "lm", 
                  predictor = "sei")
```

It is common to use a 10% level of significance because the number of studies in a meta-analysis is usually low. In the case study, the P-value is `r sprintf("%.3f", regfit$pval)`, which implies there is evidence for funnel plot asymmetry . 

Funnel plot asymmetry tests can also be performed using **metamisc** as follows:

```{r}
regfit <- fat(b = dat_os$logHR, 
              b.se = dat_os$se.logHR, 
              method = "E-FIV")
```

which yields

```{r, echo = F}
regfit
```

Again, we can construct a funnel plot:

```{r}
plot(regfit)
```

Some caution is warranted when interpreting the results for funnel plot asymmetry tests [@debray_detecting_2018]. First, the power to detect asymmetry is often limited because meta-analyses usually do not include many studies. Second, many tests are known to yield inadequate type-I error rates or to suffer from low power. For instance, it has been demonstrated that aforementioned test to evaluate the association between the estimated standard error and effect size tends to yield type-I error rates that are too high. Finally, funnel plot asymmetry may rather be caused by heterogeneity than by publication bias. We therefore adjust aforementioned regression test to use inverse of the total sample size (rather than the standard error) as predictor.

```{r,message=F,warning=F}
regtest(x = dat_os$logHR, 
        sei = dat_os$se.logHR, 
        ni = dat_os$N, 
        model = "lm", 
        predictor = "ninv")
```

From here onwards, we will assume that the potential for publication bias is negligible, and proceed with standard meta-analysis methods.

# Meta-analysis of the prognostic value of HER2

Meta-analysis is an option when the identified studies are considered sufficiently robust and comparable, and requires there are at least two estimates of the same statistic across studies. A random effects approach is often essential to allow for unexplained heterogeneity across studies due to differences in their methods, time-scale, populations, cut-points, adjustment factors, and treatments.

A standard random effects meta-analysis combines the study estimates of the statistic of interest (here given as the log HR of HER2) in order to estimate the average effect (denoted by $\mu$) and its standard deviation (denoted by $\tau$) across studies. If $\hat b_i$ and $\mathrm{var}(\hat b_i)$ denote the estimate and its variance in study $i$, then a general random effects meta-analysis model can be specified as:

$\hat b_i \sim N(\mu, \mathrm{var}(\hat b_i) + \tau^2)$

It is common to first estimate the heterogeneity parameter $\tau$ and to use the resulting value to estimate $\mu$. However, such approach does not adequately reflect the error associated with parameter estimation, especially when the number of studies is small. For this reason, alternative estimators have been proposed that simultaneously estimate $\mu$ and $\tau$. Here, we will focus on Restricted Maximum Likelihood Estimation (REML), which is implemented as default in `metafor`.

```{r,message=F,warning=F,echo=T,eval=T}
resREML <- rma(yi = logHR, sei = se.logHR, method = "REML", 
               slab = Study, data = dat_os)
resREML
```

The pooled estimate for the log hazard ratio is `r sprintf("%.3f", resREML$b)` with a standard error of `r sprintf("%.3f", sqrt(vcov(resREML)))`. The between-study standard deviation of the log hazard ratio is `r sprintf("%.3f", sqrt(resREML$tau2))`. We can extract the key statistics as follows:

```{r}
# Summary estimate of the log hazard ratio for HER2
mu <- resREML$b

# 95% confidence interval of the pooled log hazard ratio
mu.ci <- c(resREML$ci.lb, resREML$ci.ub)

# Between-study variance of the log hazard ratio
tau2 <- resREML$tau2

# Error variance of the pooled log hazard ratio
sigma2 <- as.numeric(vcov(resREML))

# Number of studies contributing to the meta-analyis
numstudies <- resREML$k.all
```

We can use the information above to derive the summary estimate for the hazard ratio and its corresponding 95% confidence interval:

```{r,message=F,warning=F,echo=T,eval=T}
exp(mu)
exp(mu.ci)
```

The summary HR of HER2 is statistically significant, indicating that increased levels of HER2 are associated with poorer survival. We can also obtain the summary estimate and 95% CI for the HR of HER2 by simply using the `predict` function:

```{r,message=F,warning=F,echo=T,eval=T}
predict(resREML, transf = exp)
```

Although the summary result ($\hat \mu$) is usually the main focus of a meta-analysis, this reflects some average across studies and it may be hard to translate to clinical practice when there is large between-study heterogeneity. We can quantify the impact of between-study heterogeneity by constructing a $100(1-\alpha/2)$% prediction interval, which gives the potential true prognostic effect in a new population conditional on the meta-analysis results [@riley_interpretation_2011]. An approximate prediction interval (PI) is given as follows:

$\hat \mu \pm t_{\alpha, N-2} \sqrt{\hat \tau^2 + \hat \sigma^2}$

where $t_{\alpha, N-2}$ is the $100(1-\alpha/2)$% percentile of the t-distribution for $N-2$ degrees of freedom, $N$ is the number of studies, $\hat \sigma$ is the estimated standard error of $\hat \mu$, and $\hat \tau$ is the estimated between-study standard deviation. In `R`, can calculate the approximate 95% PI for $\hat \mu$ as follows:

```{r,message=F,warning=F,echo=T,eval=T}
level <- 0.05
crit <- qt(c(level/2, 1-(level/2)), df = (numstudies - 2))

pi_lower <- exp(mu + crit[1] * sqrt(tau2 + sigma2))
pi_upper <- exp(mu + crit[2] * sqrt(tau2 + sigma2))

c(pi_lower, pi_upper)
```

The 95% prediction interval ranges from `r sprintf("%.3f", pi_lower)` to `r sprintf("%.3f", pi_upper)`, and suggests there is substantial heterogeneity in the prognostic value of HER2. In particular, although increased levels of HER2 are generally associated with poorer survival, they may also lead to improved survival (HR < 1) in certain settings. We can add the summary estimate and prediction interval to the forest plot:

```{r,message=F,warning=F,echo=T,eval=T, fig.width=8, fig.height=4}
# Generate a forest plot of the log hazard ratio
metamisc::forest(theta = dat_os$HR, 
                 theta.ci.lb = dat_os$HR.025, 
                 theta.ci.ub = dat_os$HR.975, 
                 theta.slab = dat_os$Study, 
                 theta.summary = exp(mu),
                 theta.summary.ci.lb = exp(mu.ci[1]),
                 theta.summary.ci.ub = exp(mu.ci[2]),
                 theta.summary.pi.lb = pi_lower,
                 theta.summary.pi.ub = pi_upper,
                 xlab = "Hazard ratio of HER2 versus OS", 
                 refline = 1)
```

A possible approach to enhance the interpretation of meta-analysis results is to calculate the probability that the prognostic effect of HER2 will be above some useful value (e.g. a HR \> 1.5 for a binary factor, which indicates risk is increased by at least 50%) in a new setting. We can calculate this probability as follows:

$Pr(\mathrm{HR} > 1.5) = Pr(\hat \mu > \log(1.5)) = 1 - Pr(\hat \mu \leq \log(1.5))$

where $Pr(\hat \mu \leq \log(1.5))$ is approximated using a scaled Student-$t$ distribution (similar to the calculation of our prediction interval):

```{r,message=F,warning=F,echo=T,eval=T}
probOS <- 1 - pt((log(1.5) - mu)/sqrt(tau2 + sigma2), df = (numstudies - 2))
probOS
```

The probability that HER2 will yield a hazard ratio for overall survival of at least 1.5 in a new setting is `r sprintf("%.0f", probOS*100)`%. This means that despite the presence of between-study heterogeneity, it is likely that HER2 will provide substantial discriminative ability when used as a single prognostic factor in a new setting. We can also estimate this probability by means of simulation:

```{r,message=F,warning=F,echo=T,eval=T}
# Simulate 100000 new studies
Nsim <- 1000000

# Random draws from a Student T distribution
rnd_t <- rt(Nsim, df = (numstudies - 2))

# Generate 1,000,000 hazard ratios
HRsim <- exp(c(mu) + rnd_t*sqrt(tau2 + sigma2))

# Calculate the proportion of hazard ratios greater than  1.5
mean(HRsim > 1.5)
```

Again, the probability that HER2 will yield a hazard ratio for overall survival of >1.5 in a new setting is `r sprintf("%.0f", mean(HRsim>1.5)*100)`%.

# Multivariate meta-analysis

In previous section, we used 14 of the 16 identified studies to evaluate the prognostic effect of HER2 on overall survival. Two studies were excluded from the meta-analysis because they did not provide direct evidence about overall survival. This is unwelcome, especially if the participants are otherwise representative of the population, clinical settings, and condition of interest [@riley_multivariate_2017]. For this reason, we here discuss how multivariate meta-analysis methods can be used to borrow strength from studies that do not investigate the primary outcome of interest. Briefly, multivariate meta-analysis methods simultaneously summarize the effect size across multiple outcomes whilst accounting for their correlation. For example, six studies in the review of @zhang_prognostic_2015 assessed the hazard ratio of HER2 for progression-free survival, four of which also assessed overall survival. Hence, by conducting a multivariate meta-analysis we can borrow strength from two additional studies when estimating the hazard ratio for overall survival. The hazard ratios for progression free survival are depicted below:

```{r kablePFS, echo=F}
out <- Zhang %>% filter(outcome == "PFS") %>%
  mutate(slabel = paste0(PrimaryAuthor, ", ", year),
                        result = paste0(HR, " (",HR.025, "; ", HR.975, ")")) %>% 
  select("slabel", "Country", "Disease", "N","result")
kable(out, col.names = c("Study", "Country", "Disease", "N", "Hazard Ratio (95% CI)"),
      align = "lccrc")
```

We first conduct a univariate meta-analysis of the six studies investigating progression-free survival:

```{r,message=F,warning=F,echo=T,eval=T}
dat_pfs <- Zhang %>% filter(outcome == "PFS")
resPFS <- rma(yi = logHR, 
              sei = se.logHR, 
              method = "REML", 
              slab = Study, 
              data = dat_pfs)
```

```{r,message=F,warning=F,echo=F,eval=T, fig.width=8, fig.height=4}
metamisc::forest(theta = dat_pfs$HR, 
                 theta.ci.lb = dat_pfs$HR.025, 
                 theta.ci.ub = dat_pfs$HR.975, 
                 theta.slab = dat_pfs$Study, 
                 theta.summary = exp(resPFS$b),
                 theta.summary.ci.lb = exp(resPFS$ci.lb),
                 theta.summary.ci.ub = exp(resPFS$ci.ub),
                 theta.summary.pi.lb = exp(mu + qt(0.025, df = (resPFS$k.all - 2)) * sqrt(resPFS$tau2 + vcov(resPFS))),
                 theta.summary.pi.ub = exp(mu + qt(0.975, df = (resPFS$k.all - 2)) * sqrt(resPFS$tau2 + vcov(resPFS))),
                 xlab = "Hazard ratio of HER2 versus PFS", 
                 refline = 1)
```

Results indicate that the hormone receptor HER2 also has prognostic value for progression-free survival. Furthermore, the reported HRs appear to be much more homogeneous across studies, since the between-study standard deviation is `r sprintf("%.2f", sqrt(resPFS$tau2))` for progression-free survival whereas it was  `r sprintf("%.2f", sqrt(resREML$tau2))` for overall survival. Note that the univariate meta-analysis for progression-free survival is based on merely 6 studies, and that the univariate meta-analysis for overall survival was based on 14 studies. We can now employ multivariate meta-analysis to borrow information from the 4 studies that report prognostic effects for both endpoints. This, in turn, allows all studies to contribute on the summary effect for HER2 in both outcomes.

We first need to define the within-study covariance matrix of the estimated log hazard ratios for progression-free survival and overall survival. We here assume that estimates for the hazard ratio are independent within studies and construct a block diagonal matrix that only considers the error variance of each estimate:

```{r,message=F,warning=F,echo=T,eval=T}
V <- diag(Zhang$se.logHR**2)
```

A multivariate random-effects model can now be used to simultaneously meta-analyze the hazard ratios for overall and progression-free survival:

```{r,message=F,warning=F,echo=T,eval=T}
res.MV <- rma.mv(yi = logHR, 
                 V = V, 
                 mods = ~ outcome - 1, 
                 random = ~ outcome | Study, 
                 struct = "UN", 
                 data = Zhang, 
                 method = "REML")
res.MV
```

The summary estimate of the log hazard ratio for overall survival is `r sprintf("%.3f", (res.MV$beta["outcomeOS",]))` (multivariate meta-analysis) versus `r sprintf("%.3f", resREML$b)` (univariate meta-analysis) with an SE of `r  sprintf("%.3f", sqrt(vcov(res.MV)["outcomeOS","outcomeOS"]))` and, respectively, `r sprintf("%.3f", sqrt(vcov(resREML)))`. Hence, we gained some precision by including evidence from 2 additional studies that only evaluated progression-free survival.

```{r,message=F,warning=F,echo=F,eval=T}
out <- data.frame(outcome = character(),
                  model = character(),
                  logHR = numeric(),
                  logHR.se = numeric(),
                  logHR.tau = numeric(),
                  HR = numeric(),
                  HR.cilower = numeric(),
                  HR.ciupper = numeric())

out <- out %>% add_row(data.frame(outcome = "Overall Survival",
                                  model = "Univariate meta-analysis",
                                  logHR = resREML$b,
                                  logHR.se = sqrt(as.numeric(vcov(resREML))),
                                  logHR.tau = sqrt(resREML$tau2),
                                  HR = exp(resREML$b),
                                  HR.cilower = exp(resREML$ci.lb),
                                  HR.ciupper = exp(resREML$ci.ub)))
out <- out %>% add_row(data.frame(outcome = "Overall Survival",
                                  model = "Multivariate meta-analysis",
                                  logHR = res.MV$beta["outcomeOS",],
                                  logHR.se =  sqrt(vcov(res.MV)["outcomeOS","outcomeOS"]),
                                  logHR.tau = sqrt(res.MV$tau2[1]),
                                  HR = exp(res.MV$beta["outcomeOS",]),
                                  HR.cilower = exp(res.MV$ci.lb)[1],
                                  HR.ciupper = exp(res.MV$ci.ub)[1]))
out <- out %>% add_row(data.frame(outcome = "Progression-free Survival",
                                  model = "Univariate meta-analysis",
                                  logHR = resPFS$b,
                                  logHR.se = sqrt(as.numeric(vcov(resPFS))),
                                  logHR.tau = sqrt(resPFS$tau2),
                                  HR = exp(resPFS$b),
                                  HR.cilower = exp(resPFS$ci.lb),
                                  HR.ciupper = exp(resPFS$ci.ub)))
out <- out %>% add_row(data.frame(outcome = "Progression-free Survival",
                                  model = "Multivariate meta-analysis",
                                  logHR = res.MV$beta["outcomePFS",],
                                  logHR.se =  sqrt(vcov(res.MV)["outcomePFS","outcomePFS"]),
                                  logHR.tau = sqrt(res.MV$tau2[2]),
                                  HR = exp(res.MV$beta["outcomePFS",]),
                                  HR.cilower = exp(res.MV$ci.lb)[2],
                                  HR.ciupper = exp(res.MV$ci.ub)[2]))

kout <- out %>% mutate(logHR =  sprintf("%.3f", logHR),
                       logHR.se =  sprintf("%.3f", logHR.se),
                       logHR.tau =  sprintf("%.3f", logHR.tau),
                         HR = sprintf("%.2f", HR),
                       HRci = paste0(sprintf("%.2f",HR.cilower), "; ", sprintf("%.2f",HR.ciupper))) %>% 
  select(outcome, model, logHR, logHR.se, logHR.tau, HR, HRci)
kable(kout, col.names = c("Outcome", "Model", "$\\mu$", "SE($\\mu$)", "$\\tau$", "HR", "95% CI"),
      align = "llccc")
```

Note that estimation of between-study heterogeneity was difficult for progression-free survival due to the limited number of studies. In particular, we found $\tau^2$= `r sprintf("%.3f", resPFS$tau2)` with an SE of `r sprintf("%.3f", resPFS$se.tau2)`. In the multivariate meta-analysis, the estimated between-study variance for PFS was much larger ($\tau^2$=`r sprintf("%.3f", res.MV$tau2[2])`), and based on all 16 rather than merely 6 studies.

In summary, the multivariate meta-analysis approach is often helpful as it reduces the need to exclude relevant studies from a meta-analysis, thereby decreasing the risk of bias (e.g. due to selective outcome reporting) and potentially improving precision. As indicated by @riley_multivariate_2017, a multivariate meta-analysis of multiple outcomes is most beneficial when the outcomes are highly correlated and the percentage of studies with missing outcomes is large.


# References
